---
date: 2025-01-03
title: 'From DataPLANT’s DataHUB to DataPUB(lication)' officially published
description: "A core document describing one of the central objectives of the DataPLANT consortium has been published by our partner, 
the University Library of Tübingen. One of the major development tasks in our project was to provide a science gateway 
as a technical foundation that applies software engineering-inspired approaches to data management ..."
---
A core document describing one of the central objectives of the DataPLANT consortium has been published by our partner, 
the University Library of Tübingen. One of the major development tasks in our project was to provide a science gateway 
as a technical foundation that applies software engineering-inspired approaches to data management and makes them 
accessible to plant researchers. The [document outlines the PLANT DataHUB](https://doi.org/10.15496/publikation-100323)
([HDL](http://hdl.handle.net/10900/158990)), which delivers various RDM workflows to support research data scientists 
throughout the data life cycle—from the annotation and structuring of collected data to the publication of the resulting
insights.

To foster cultural change, we aim to support formal data publication with DOIs or comparable persistent resolvers, 
aligning with the evolving scientific landscape and advancing developments in plant research toward Open Science and 
Open Data. The technical platform adheres to the [ARC principle of being "Immutable yet evolving."](https://doi.org/10.11588/heibooks.979.c13751) 
Data publications, via domain-specific repositories or the [DataPLANT ARChive](https://archive.nfdi4plants.org/), provide 
opportunities to publish "frozen in time" versions that are stable and citable, not limited to the end of the research 
process. [This paper was presented at the IWSG in Tübingen in 2023](2023-06-16-dataplant-participated-in-the-15th-international-workshop-on-science-gateways/).

This initiative aligns with DataPLANT's strategy to empower users by enabling participation and establishing a clear 
strategy for quality assurance through automation and tooling. In the proposed second funding phase, this strategy 
includes expanding and automating validation processes with unit testing, ensuring no user is prevented from sharing 
their data while enabling collaborative improvements over time. Automation enhances data quality by ensuring metadata 
completeness and measurement quality, with quality control workflows tailored to specific measurements and implemented 
by data experts or method developers. Moreover, automatic reproduction triggers can verify long-term reproducibility.
